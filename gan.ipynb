{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "WM52_mv6OEge"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "#import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from IPython import display\n",
    "from PIL import Image\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymBBzR7fP65l"
   },
   "source": [
    "# Use to mount Gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCV4BW0sPNXG"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSLgMKcpPNZp"
   },
   "outputs": [],
   "source": [
    "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
    "!ls /mydrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WXc2dF8lPQH_"
   },
   "outputs": [],
   "source": [
    "!cp /mydrive/images.zip ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-V8D9UYjPQKH"
   },
   "outputs": [],
   "source": [
    "!unzip ../images.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tsnk4QJtOEgf"
   },
   "source": [
    "# Load images from folder and to a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6_D8vkxKPWlf"
   },
   "outputs": [],
   "source": [
    "filelist=\"./images/*.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "yizsaoq6OEgf"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "all_images = []\n",
    "for index, filename in enumerate(glob.glob(filelist)):\n",
    "    image = cv.imread(filename)\n",
    "    all_images.append(image)\n",
    "\n",
    "X = np.array(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [ 42,  31,  56],\n",
       "         [ 33,  28,  48],\n",
       "         [ 29,  31,  35]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [ 44,  46,  67],\n",
       "         [ 31,  32,  44],\n",
       "         [ 27,  24,  40]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [ 70,  71,  97],\n",
       "         [ 30,  30,  44],\n",
       "         [ 27,  24,  40]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[129,  92,  87],\n",
       "         [125, 100,  97],\n",
       "         [241, 244, 243],\n",
       "         ...,\n",
       "         [160, 129, 134],\n",
       "         [237, 222, 226],\n",
       "         [255, 251, 253]],\n",
       "\n",
       "        [[132,  95,  92],\n",
       "         [111,  78,  75],\n",
       "         [195, 191, 189],\n",
       "         ...,\n",
       "         [220, 193, 202],\n",
       "         [247, 243, 244],\n",
       "         [253, 254, 254]],\n",
       "\n",
       "        [[112,  85,  83],\n",
       "         [128,  95,  92],\n",
       "         [119,  98,  96],\n",
       "         ...,\n",
       "         [233, 217, 224],\n",
       "         [255, 255, 255],\n",
       "         [251, 252, 252]]],\n",
       "\n",
       "\n",
       "       [[[ 55,  77, 146],\n",
       "         [ 55,  81, 164],\n",
       "         [ 69,  96, 180],\n",
       "         ...,\n",
       "         [ 40,  60, 129],\n",
       "         [ 40,  61, 135],\n",
       "         [ 47,  60, 123]],\n",
       "\n",
       "        [[ 60,  81, 155],\n",
       "         [ 50,  74, 156],\n",
       "         [ 79, 102, 188],\n",
       "         ...,\n",
       "         [ 38,  59, 126],\n",
       "         [ 38,  60, 133],\n",
       "         [ 47,  60, 129]],\n",
       "\n",
       "        [[ 47,  75, 149],\n",
       "         [ 57,  77, 163],\n",
       "         [ 78,  99, 187],\n",
       "         ...,\n",
       "         [ 40,  59, 126],\n",
       "         [ 40,  62, 135],\n",
       "         [ 44,  57, 131]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[151, 115, 233],\n",
       "         [148, 107, 234],\n",
       "         [125,  78, 223],\n",
       "         ...,\n",
       "         [131, 125, 148],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[145, 108, 235],\n",
       "         [149, 111, 236],\n",
       "         [153, 110, 241],\n",
       "         ...,\n",
       "         [ 77,  53, 119],\n",
       "         [111, 107, 120],\n",
       "         [192, 192, 191]],\n",
       "\n",
       "        [[151, 108, 240],\n",
       "         [145, 109, 234],\n",
       "         [150, 111, 234],\n",
       "         ...,\n",
       "         [112,  77, 173],\n",
       "         [181, 175, 190],\n",
       "         [192, 193, 192]]],\n",
       "\n",
       "\n",
       "       [[[ 81,  59, 194],\n",
       "         [109,  86, 224],\n",
       "         [105,  82, 225],\n",
       "         ...,\n",
       "         [ 68,  51, 169],\n",
       "         [ 89,  71, 188],\n",
       "         [ 81,  63, 173]],\n",
       "\n",
       "        [[ 92,  69, 206],\n",
       "         [112,  88, 229],\n",
       "         [107,  83, 224],\n",
       "         ...,\n",
       "         [ 55,  38, 138],\n",
       "         [ 77,  58, 168],\n",
       "         [ 74,  55, 166]],\n",
       "\n",
       "        [[111,  90, 219],\n",
       "         [135, 112, 246],\n",
       "         [111,  81, 234],\n",
       "         ...,\n",
       "         [ 51,  33, 128],\n",
       "         [ 60,  42, 143],\n",
       "         [ 66,  48, 150]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[239, 206, 224],\n",
       "         [234, 202, 216],\n",
       "         [237, 206, 220],\n",
       "         ...,\n",
       "         [ 52,  27, 132],\n",
       "         [ 72,  46, 149],\n",
       "         [ 79,  43, 152]],\n",
       "\n",
       "        [[233, 202, 218],\n",
       "         [233, 203, 217],\n",
       "         [227, 197, 212],\n",
       "         ...,\n",
       "         [ 74,  48, 130],\n",
       "         [ 54,  31, 123],\n",
       "         [ 57,  36, 141]],\n",
       "\n",
       "        [[235, 210, 222],\n",
       "         [229, 205, 217],\n",
       "         [228, 202, 216],\n",
       "         ...,\n",
       "         [191, 140, 180],\n",
       "         [168, 123, 170],\n",
       "         [136,  97, 159]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 81,  67,  99],\n",
       "         [105, 127, 148],\n",
       "         [109, 255, 253],\n",
       "         ...,\n",
       "         [ 46,  80,  94],\n",
       "         [ 75,  54,  83],\n",
       "         [ 55,  45,  66]],\n",
       "\n",
       "        [[ 87,  75, 106],\n",
       "         [115, 171, 182],\n",
       "         [ 71, 241, 240],\n",
       "         ...,\n",
       "         [ 40, 138, 143],\n",
       "         [ 73,  47,  77],\n",
       "         [ 55,  43,  65]],\n",
       "\n",
       "        [[ 88,  82, 115],\n",
       "         [101, 202, 206],\n",
       "         [ 57, 234, 235],\n",
       "         ...,\n",
       "         [ 63, 217, 212],\n",
       "         [ 57,  33,  66],\n",
       "         [ 49,  46,  66]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[100,  76, 116],\n",
       "         [ 23,  12,  29],\n",
       "         [187, 183, 185],\n",
       "         ...,\n",
       "         [118,  57,  49],\n",
       "         [117,  57,  49],\n",
       "         [120,  61,  53]],\n",
       "\n",
       "        [[115,  83, 125],\n",
       "         [ 55,  37,  59],\n",
       "         [118, 115, 121],\n",
       "         ...,\n",
       "         [128,  75,  61],\n",
       "         [118,  64,  50],\n",
       "         [120,  65,  54]],\n",
       "\n",
       "        [[ 94,  63, 100],\n",
       "         [ 99,  70, 110],\n",
       "         [ 63,  56,  69],\n",
       "         ...,\n",
       "         [171, 112,  86],\n",
       "         [170, 107,  85],\n",
       "         [164,  98,  80]]],\n",
       "\n",
       "\n",
       "       [[[134,  87,  73],\n",
       "         [134,  87,  71],\n",
       "         [122,  78,  64],\n",
       "         ...,\n",
       "         [250, 255, 255],\n",
       "         [255, 255, 252],\n",
       "         [255, 255, 253]],\n",
       "\n",
       "        [[133,  88,  75],\n",
       "         [120,  76,  63],\n",
       "         [128,  90,  75],\n",
       "         ...,\n",
       "         [250, 254, 255],\n",
       "         [254, 254, 252],\n",
       "         [253, 253, 251]],\n",
       "\n",
       "        [[123,  80,  72],\n",
       "         [105,  66,  55],\n",
       "         [115,  80,  66],\n",
       "         ...,\n",
       "         [250, 254, 255],\n",
       "         [251, 255, 252],\n",
       "         [253, 254, 252]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 47,  27,  24],\n",
       "         [ 53,  33,  29],\n",
       "         [ 50,  24,  18],\n",
       "         ...,\n",
       "         [ 87,  55,  45],\n",
       "         [114,  79,  71],\n",
       "         [ 79,  50,  43]],\n",
       "\n",
       "        [[ 47,  25,  20],\n",
       "         [ 56,  29,  21],\n",
       "         [ 81,  48,  37],\n",
       "         ...,\n",
       "         [ 91,  51,  42],\n",
       "         [111,  73,  67],\n",
       "         [ 87,  55,  50]],\n",
       "\n",
       "        [[107,  68,  48],\n",
       "         [140,  96,  72],\n",
       "         [143,  95,  71],\n",
       "         ...,\n",
       "         [156, 101,  78],\n",
       "         [139,  88,  70],\n",
       "         [113,  66,  50]]],\n",
       "\n",
       "\n",
       "       [[[115, 134, 161],\n",
       "         [103, 123, 146],\n",
       "         [174, 193, 213],\n",
       "         ...,\n",
       "         [ 99, 114, 133],\n",
       "         [136, 145, 161],\n",
       "         [244, 246, 250]],\n",
       "\n",
       "        [[110, 127, 150],\n",
       "         [115, 132, 151],\n",
       "         [166, 183, 200],\n",
       "         ...,\n",
       "         [102, 119, 142],\n",
       "         [101, 112, 136],\n",
       "         [201, 204, 213]],\n",
       "\n",
       "        [[100, 115, 135],\n",
       "         [139, 152, 168],\n",
       "         [158, 173, 189],\n",
       "         ...,\n",
       "         [119, 140, 162],\n",
       "         [ 96, 104, 132],\n",
       "         [125, 127, 139]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [254, 254, 254]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [253, 252, 252],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [253, 253, 255],\n",
       "         [254, 252, 252],\n",
       "         [253, 251, 251]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [250, 250, 250],\n",
       "         ...,\n",
       "         [249, 252, 250],\n",
       "         [252, 254, 253],\n",
       "         [250, 254, 252]]]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "uWLfPYSeOEgf"
   },
   "outputs": [],
   "source": [
    "train_images = X.reshape(X.shape[0], 64 , 64 , 3).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-aNf0NRKOEgf"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE =1000\n",
    "BATCH_SIZE = 128\n",
    "#batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BqeSbRPeOEgf"
   },
   "outputs": [],
   "source": [
    "inputshape=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzhY7KYuOEgf"
   },
   "source": [
    "# Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_1QQn2sOEgf"
   },
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(inputshape,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((8, 8, 256)))\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-uUd-FWOEgf"
   },
   "outputs": [],
   "source": [
    "make_generator_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPoMSKEVOEgh"
   },
   "outputs": [],
   "source": [
    "#noise = tf.random.normal([1, 100])\n",
    "z = np.random.uniform(-1., 1., size=[1, inputshape])\n",
    "#noise\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CETY1b2XOEgh"
   },
   "outputs": [],
   "source": [
    "generator = make_generator_model()\n",
    "generated_image = generator(z, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fn9PiwQXOEgh"
   },
   "source": [
    "# Discriminatior Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUyGOI03OEgh"
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[64, 64, 3]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVNWv_HMOEgh"
   },
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRKc_PFTOEgh"
   },
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-v9pUi_rOEgh"
   },
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEfDbxprOEgh"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4w2TxL4OEgh"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lL20PhQcOEgh"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTjZ1USwOEgh"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOU4Ryn4OEgh"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10000\n",
    "noise_dim = inputshape\n",
    "num_examples_to_generate = 1\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BxzjpXVyOEgh"
   },
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    #noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    noise = np.random.uniform(-1., 1., size=[BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozL8R4qeOEgh"
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        for a in dataset:\n",
    "            train_step(a)\n",
    "\n",
    "        # Produce images for the GIF as we go\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator,\n",
    "                                 epoch + 1,\n",
    "                                 seed)\n",
    "\n",
    "        # Save the model every 200 epochs\n",
    "        if (epoch + 1) % 200 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "    #Generate after the final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJ2UfsUIOEgh"
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    #plt.imshow(predictions[0])\n",
    "    plt.imshow(predictions[0])\n",
    "    #for i in range(predictions.shape[0]):\n",
    "    #    plt.subplot(4, 4, i+1)\n",
    "     #   plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5)\n",
    "    #    plt.axis('off')\n",
    "    pa=\"./sav/\"\n",
    "    na=epoch\n",
    "    ex=\".png\"\n",
    "    plt.savefig(pa+str(epoch)+ex)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9D8UO5mOEgi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwQDARD6OEgi"
   },
   "outputs": [],
   "source": [
    "z1=np.random.uniform(-1., 1., size=[1, inputshape])\n",
    "predictions = generator(z1, training=False)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.imshow(predictions[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gAQlzPrOOEgi"
   },
   "outputs": [],
   "source": [
    "plt.imshow(predictions[0, :, :, 0] * 127.5 + 127.5, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwXS4T9GOEgi"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.imshow(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqSESoFzOEgi"
   },
   "source": [
    "# Prediction with random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g16FHlntOEgi"
   },
   "outputs": [],
   "source": [
    "for i in range (0,5):\n",
    "    z1=np.random.uniform(-1., 1., size=[1, inputshape])\n",
    "    predictions = generator(z1, training=False)\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    plt.imshow(predictions[0])\n",
    "    \"\"\"pa=\"./aa/\"\n",
    "    na=i\n",
    "    ex=\".png\"\n",
    "    plt.savefig(pa+str(na)+ex)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3UqvwBLCOEgi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kl95vQ1EOEgi"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rm9nVsuKOEgi"
   },
   "source": [
    "# Restore checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXweuDdAOEgi"
   },
   "outputs": [],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWTurfGpOEgi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "gan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
